{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carvana Image Masking Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for the solution in Kaggle's Carvana Image Masking Challenge on car segmentation (https://www.kaggle.com/c/carvana-image-masking-challenge).\n",
    "\n",
    "We used U-Net to segment a car in the image. This Blogpost explaining the solution: https://www.novatec-gmbh.de/blog/semantic-segmentation-part-2-training-u-net/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the final model we used the following hardware and software:\n",
    "\n",
    "- OS: Ubuntu 18.04 Server\n",
    "- Hardware: CPU Intel Core i7-7700k 64 Gb Ram\n",
    "- Required hardware: Any decent modern computer with x86-64 CPU, minimum 32 GB RAM\n",
    "- Powerful GPU\n",
    "\n",
    "Main software for training neural networks:\n",
    "- Python 3.5\n",
    "- CUDA \n",
    "- Tensorflow-GPU and Tensorflow, Keras\n",
    "\n",
    "Data:\n",
    "\n",
    "Generate the required data paths in '\\data' and put in the datasets you downloaded on the Kaggle website.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import misc, ndimage\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import transform\n",
    "from tqdm import tqdm\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train')\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test')\n",
    "TRAIN_MASKS_PATH = os.path.join(DATA_PATH, 'train_masks')\n",
    "TRAIN_MASKS_CSV_PATH = os.path.join(DATA_PATH, 'train_masks.csv')\n",
    "SAMPLE_SUBMISSION_PATH = os.path.join(DATA_PATH, 'sample_submission.csv')\n",
    "METADATA_PATH = os.path.join(DATA_PATH, 'metadata.csv')\n",
    "SUBMISSION_PATH = os.path.join(DATA_PATH, 'submissions')\n",
    "MODELS_PATH = os.path.join(DATA_PATH, 'models')\n",
    "TENSORBOARD_PATH = os.path.join(DATA_PATH, 'tensorboard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks_df = pd.read_csv(TRAIN_MASKS_CSV_PATH)\n",
    "print('train_masks_df.shape', train_masks_df.shape)\n",
    "train_masks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define methods and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "HEIGHT_ORIG = 1280\n",
    "WIDTH_ORIG = 1918\n",
    "CHANNELS_ORIG = 3\n",
    "\n",
    "HEIGHT = 1024\n",
    "WIDTH = 1024\n",
    "CHANNELS = 3\n",
    "new_shape = (HEIGHT, WIDTH, CHANNELS)\n",
    "mask_shape = (new_shape[0], new_shape[1], 1)\n",
    "\n",
    "def get_img_id(img_path):\n",
    "    return img_path[:15]\n",
    "\n",
    "img_ids = list(map(get_img_id, list(train_masks_df.img.values)))\n",
    "\n",
    "def load_image_disk(img_id, folder=TRAIN_PATH):\n",
    "    img = misc.imread(os.path.join(folder, img_id + \".jpg\"))\n",
    "    return img\n",
    "\n",
    "def get_image(img_id):\n",
    "    return train_imgs[img_id]\n",
    "\n",
    "# Return mask as 1/0 binary img with single channel\n",
    "def load_mask_disk(img_id, folder=TRAIN_MASKS_PATH, filetype='gif'):\n",
    "    mask = misc.imread(os.path.join(folder,  \"{}_mask.{}\".format(img_id, filetype)), flatten=True)\n",
    "    mask[mask > 128] = 1\n",
    "    if len(mask.shape) == 2:\n",
    "        mask = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    return mask\n",
    "\n",
    "def get_mask(img_id):\n",
    "    return train_masks[img_id]\n",
    "\n",
    "# Helper functions to plot car, mask, masked_car\n",
    "def plot_image(img_id):\n",
    "    img = misc.imread(os.path.join(TRAIN_PATH, img_id + \".jpg\"))\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mask(img_id, folder=TRAIN_MASKS_PATH, filetype='gif', ax=None):\n",
    "    mask = misc.imread(os.path.join(folder, \"{}_mask.{}\".format(img_id, filetype)))\n",
    "    if ax == None:\n",
    "        imgplot = plt.imshow(mask)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.imshow(mask)\n",
    "        ax.axis('off')\n",
    "    \n",
    "def plot_masked_image(img_id, ax=None):\n",
    "    img = misc.imread(os.path.join(TRAIN_PATH, img_id + \".jpg\"))\n",
    "    mask = misc.imread(os.path.join(TRAIN_MASKS_PATH, img_id + \"_mask.gif\"))\n",
    "    mask = mask[:,:,0:3]\n",
    "    mask[mask == 255] = 1 \n",
    "    masked_img = img * mask\n",
    "    if ax == None:\n",
    "        imgplot = plt.imshow(masked_img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.imshow(masked_img)\n",
    "        ax.axis('off')\n",
    "\n",
    "def gray2rgb(img):\n",
    "    img = np.squeeze(img)\n",
    "    w, h = img.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = img\n",
    "    ret[:, :, 1] = img\n",
    "    ret[:, :, 2] = img\n",
    "    return ret\n",
    "\n",
    "def resize_img(img, new_s = new_shape):\n",
    "    return transform.resize(img, new_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read images and masks into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training images into memory\n",
    "train_imgs = {}\n",
    "for img_path in tqdm(os.listdir(TRAIN_PATH)):\n",
    "    img_id = get_img_id(img_path)\n",
    "    train_imgs[img_id] = cv2.resize(load_image_disk(img_id), (new_shape[0], new_shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training masks into memory\n",
    "train_masks = {}\n",
    "for img_path in tqdm(os.listdir(TRAIN_MASKS_PATH)):\n",
    "    img_id = get_img_id(img_path)\n",
    "    train_masks[img_id] = np.expand_dims(cv2.resize(load_mask_disk(img_id), (new_shape[0], new_shape[1])), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Augmentation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomHueSaturationValue(image, hue_shift_limit=(-180, 180),\n",
    "                             sat_shift_limit=(-255, 255),\n",
    "                             val_shift_limit=(-255, 255), u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        h, s, v = cv2.split(image)\n",
    "        hue_shift = np.random.uniform(hue_shift_limit[0], hue_shift_limit[1])\n",
    "        h = cv2.add(h, hue_shift)\n",
    "        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n",
    "        s = cv2.add(s, sat_shift)\n",
    "        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n",
    "        v = cv2.add(v, val_shift)\n",
    "        image = cv2.merge((h, s, v))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "    return image\n",
    "\n",
    "def randomShiftScaleRotate(image, mask,\n",
    "                           shift_limit=(-0.0625, 0.0625),\n",
    "                           scale_limit=(-0.1, 0.1),\n",
    "                           rotate_limit=(-45, 45), aspect_limit=(0, 0),\n",
    "                           borderMode=cv2.BORDER_REFLECT_101, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        height, width, channel = image.shape\n",
    "\n",
    "        angle = np.random.uniform(rotate_limit[0], rotate_limit[1])  # degree\n",
    "        scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n",
    "        aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n",
    "        sx = scale * aspect / (aspect ** 0.5)\n",
    "        sy = scale / (aspect ** 0.5)\n",
    "        dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)\n",
    "        dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)\n",
    "\n",
    "        cc = np.math.cos(angle / 180 * np.math.pi) * sx\n",
    "        ss = np.math.sin(angle / 180 * np.math.pi) * sy\n",
    "        rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    "\n",
    "        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])\n",
    "        box1 = box0 - np.array([width / 2, height / 2])\n",
    "        box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])\n",
    "\n",
    "        box0 = box0.astype(np.float32)\n",
    "        box1 = box1.astype(np.float32)\n",
    "        mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "        image = cv2.warpPerspective(image, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                    borderValue=(0, 0, 0,))\n",
    "        mask = cv2.warpPerspective(mask, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                   borderValue=(0, 0, 0,))\n",
    "        if len(mask.shape) == 2:\n",
    "            mask = np.expand_dims(mask, axis=2)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def randomHorizontalFlip(image, mask, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.flip(image, 1)\n",
    "        mask = cv2.flip(mask, 1)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define methods for batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_batch(data, batch_size):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        batch_ids = np.random.choice(data,\n",
    "                                     size=batch_size,\n",
    "                                     replace=False)\n",
    "        for idx, img_id in enumerate(batch_ids):\n",
    "            x = get_image(img_id)\n",
    "            y = get_mask(img_id)\n",
    "            x, y = randomShiftScaleRotate(x, y,\n",
    "                                          shift_limit=(-0.0625, 0.0625),\n",
    "                                          scale_limit=(-0.1, 0.1),\n",
    "                                          rotate_limit=(-0, 0))\n",
    "            x = randomHueSaturationValue(x,\n",
    "                                hue_shift_limit=(-50, 50),\n",
    "                                sat_shift_limit=(-5, 5),\n",
    "                                val_shift_limit=(-15, 15))\n",
    "            X_batch.append(x)\n",
    "            Y_batch.append(y)\n",
    "        X = np.asarray(X_batch, dtype=np.float32)\n",
    "        Y = np.asarray(Y_batch, dtype=np.float32)\n",
    "        yield X, Y\n",
    "\n",
    "def generate_validation_batch(data, batch_size):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        batch_ids = np.random.choice(data,\n",
    "                                     size=batch_size,\n",
    "                                     replace=False)\n",
    "        for idx, img_id in enumerate(batch_ids):\n",
    "            x = get_image(img_id)\n",
    "            y = get_mask(img_id)\n",
    "            X_batch.append(x)\n",
    "            Y_batch.append(y)\n",
    "        X = np.asarray(X_batch, dtype=np.float32)\n",
    "        Y = np.asarray(Y_batch, dtype=np.float32)\n",
    "        yield X, Y\n",
    "\n",
    "def generate_validation_data_seq(data):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        img_id = data[idx]\n",
    "        X = get_image(img_id)\n",
    "        Y = get_mask(img_id)\n",
    "        yield img_id, X, Y\n",
    "        idx  += 1\n",
    "        if idx >= len(data):\n",
    "            break\n",
    "\n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "    non_trainable_count = int(np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n",
    "\n",
    "    total_memory = 4*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = round(total_memory / (1024 ** 3), 3)\n",
    "    mbytes = round(total_memory / (1024 ** 2), 3)\n",
    "    \n",
    "    print('trainable_count', trainable_count, 'non_trainable_count', non_trainable_count, 'gbytes', gbytes, 'mbytes', mbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of random shift scale rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize impact of random shift scale rotate\n",
    "random_idx = np.random.randint(len(train_imgs.keys()))\n",
    "random_img_id = list(train_imgs.keys())[random_idx]\n",
    "plot_image(random_img_id)\n",
    "temp_img = get_image(random_img_id)\n",
    "mask = get_mask(random_img_id)\n",
    "temp_img, temp_mask = randomShiftScaleRotate(temp_img, mask,\n",
    "                              shift_limit=(-0.0625, 0.0625),\n",
    "                              scale_limit=(-0.1, 0.1),\n",
    "                              rotate_limit=(-0, 0))\n",
    "\n",
    "plt.imshow(temp_img * gray2rgb(temp_mask))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of random hue saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize impact of random hue saturation\n",
    "random_idx = np.random.randint(len(train_imgs.keys()))\n",
    "random_img_id = list(train_imgs.keys())[random_idx]\n",
    "plot_image(random_img_id)\n",
    "temp_img = cv2.imread(os.path.join(TRAIN_PATH, '{}.jpg'.format(random_img_id)))\n",
    "temp_img = randomHueSaturationValue(temp_img,\n",
    "                               hue_shift_limit=(-50, 50),\n",
    "                               sat_shift_limit=(-5, 5),\n",
    "                               val_shift_limit=(-15, 15))\n",
    "plt.imshow(temp_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down(filters, input_):\n",
    "    down_ = Conv2D(filters, (3, 3), padding='same')(input_)\n",
    "    down_ = BatchNormalization(epsilon=1e-4)(down_)\n",
    "    down_ = Activation('relu')(down_)\n",
    "    down_ = Conv2D(filters, (3, 3), padding='same')(down_)\n",
    "    down_ = BatchNormalization(epsilon=1e-4)(down_)\n",
    "    down_res = Activation('relu')(down_)\n",
    "    down_pool = MaxPooling2D((2, 2), strides=(2, 2))(down_)\n",
    "    return down_pool, down_res\n",
    "\n",
    "def up(filters, input_, down_):\n",
    "    up_ = UpSampling2D((2, 2))(input_)\n",
    "    up_ = concatenate([down_, up_], axis=3)\n",
    "    up_ = Conv2D(filters, (3, 3), padding='same')(up_)\n",
    "    up_ = BatchNormalization(epsilon=1e-4)(up_)\n",
    "    up_ = Activation('relu')(up_)\n",
    "    up_ = Conv2D(filters, (3, 3), padding='same')(up_)\n",
    "    up_ = BatchNormalization(epsilon=1e-4)(up_)\n",
    "    up_ = Activation('relu')(up_)\n",
    "    up_ = Conv2D(filters, (3, 3), padding='same')(up_)\n",
    "    up_ = BatchNormalization(epsilon=1e-4)(up_)\n",
    "    up_ = Activation('relu')(up_)\n",
    "    return up_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_1024(input_shape=(HEIGHT, WIDTH, CHANNELS), num_classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        #down0b, down0b_res = down(8, inputs)\n",
    "        down0a, down0a_res = down(24, inputs)\n",
    "        down0, down0_res = down(64, down0a)\n",
    "        down1, down1_res = down(128, down0)\n",
    "        down2, down2_res = down(256, down1)\n",
    "        down3, down3_res = down(512, down2)\n",
    "        down4, down4_res = down(768, down3)\n",
    "\n",
    "        center = Conv2D(768, (3, 3), padding='same')(down4)\n",
    "        center = BatchNormalization(epsilon=1e-4)(center)\n",
    "        center = Activation('relu')(center)\n",
    "        \n",
    "    with tf.device('/gpu:1'):\n",
    "        center = Conv2D(768, (3, 3), padding='same')(center)\n",
    "        center = BatchNormalization(epsilon=1e-4)(center)\n",
    "        center = Activation('relu')(center)\n",
    "\n",
    "        up4 = up(768, center, down4_res)\n",
    "        up3 = up(512, up4, down3_res)\n",
    "        up2 = up(256, up3, down2_res)\n",
    "        up1 = up(128, up2, down1_res)\n",
    "        up0 = up(64, up1, down0_res)\n",
    "        up0a = up(24, up0, down0a_res)\n",
    "        #up0b = up(8, up0a, down0b_res)\n",
    "\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid', name='final_layer')(up0a)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dice Coef evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    \n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "    (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_coef(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    return score\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    return 1. - weighted_dice_coef(y_true, y_pred, weight)\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    averaged_mask = K.pool2d(y_true, pool_size=(11, 11), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.01), 'float32') * K.cast(K.less(averaged_mask, 0.99), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + weighted_dice_loss(y_true, y_pred, weight)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "# Training new model\n",
    "ts = str(int(time.time()))\n",
    "model_name = 'malhot'\n",
    "num_epochs = 30\n",
    "steps_per_epoch = int(len(img_ids) * 0.8/BATCH_SIZE)\n",
    "run_name = 'model={}-batch_size={}-num_epoch={}-steps_per_epoch={}-ts={}'.format(model_name,\n",
    "                                                                          BATCH_SIZE,\n",
    "                                                                          num_epochs,\n",
    "                                                                          steps_per_epoch,\n",
    "                                                                          ts)\n",
    "tensorboard_loc = os.path.join(TENSORBOARD_PATH, run_name)\n",
    "checkpoint_loc = os.path.join(MODELS_PATH,'model-1555053470.h5')\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience=2, \n",
    "                              verbose=1, \n",
    "                              min_delta = 0.0001,\n",
    "                              mode='min',)\n",
    "\n",
    "modelCheckpoint = ModelCheckpoint(checkpoint_loc,\n",
    "                                  monitor = 'val_loss', \n",
    "                                  save_best_only = True, \n",
    "                                  mode = 'min', \n",
    "                                  verbose = 1,\n",
    "                                  save_weights_only = True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=tensorboard_loc, histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks_list = [modelCheckpoint, earlyStopping, tensorboard]\n",
    "\n",
    "model = get_unet_1024()\n",
    "model.compile(loss=bce_dice_loss, optimizer=Adam(lr=1e-4), metrics=[dice_coef])\n",
    "print(model.summary())\n",
    "get_model_memory_usage(BATCH_SIZE, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Re-training old model\n",
    "ts = str(int(time.time()))\n",
    "model_name = 'malhot'\n",
    "num_epochs = 300\n",
    "steps_per_epoch = 101\n",
    "run_name = 'model={}-batch_size={}-num_epoch={}-steps_per_epoch={}-ts={}'.format(model_name,\n",
    "                                                                          BATCH_SIZE,\n",
    "                                                                          num_epochs,\n",
    "                                                                          steps_per_epoch,\n",
    "                                                                          ts)\n",
    "tensorboard_loc = os.path.join(TENSORBOARD_PATH, run_name)\n",
    "checkpoint_loc = os.path.join(MODELS_PATH, 'model-1555053470.h5')\n",
    "\n",
    "modelCheckpoint = ModelCheckpoint(checkpoint_loc,\n",
    "                                  monitor = 'val_loss', \n",
    "                                  save_best_only = True, \n",
    "                                  mode = 'min', \n",
    "                                  verbose = 1,\n",
    "                                  save_weights_only = True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=tensorboard_loc, histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks_list = [modelCheckpoint, tensorboard]\n",
    "\n",
    "model = get_unet_1024()\n",
    "model.load_weights(os.path.join(MODELS_PATH, 'model-1555053470.h5'))\n",
    "model.compile(loss=weighted_bce_dice_loss, optimizer=Adam(lr=1e-5), metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, validation_ids = model_selection.train_test_split(img_ids, random_state=42, test_size=0.20)\n",
    "train_generator = generate_training_batch(train_ids, BATCH_SIZE)\n",
    "valid_generator = generate_validation_batch(validation_ids, BATCH_SIZE)\n",
    "VALIDATION_STEPS = int(len(validation_ids) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet_1024()\n",
    "model.load_weights(os.path.join(MODELS_PATH, 'model-1555053470.h5'))\n",
    "model.compile(loss=bce_dice_loss, optimizer=Adam(1e-5), metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(valid_generator, VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_dices = []\n",
    "for img_id, X, Y in generate_validation_data_seq(validation_ids):\n",
    "    error = model.evaluate(np.expand_dims(X, axis=0), np.expand_dims(Y, axis=0), verbose=0)\n",
    "    validation_dices.append((img_id, error[0], error[1]))\n",
    "\n",
    "val_eval_df = pd.DataFrame.from_records(validation_dices, columns=['img_id', 'val_loss', 'dice_coef'])\n",
    "val_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_eval_df.to_csv(os.path.join(DATA_PATH, 'val_eval_df-1506223599.csv'), index=False)\n",
    "val_eval_df = pd.read_csv(os.path.join(DATA_PATH, 'val_eval_df-1506223599.csv'))\n",
    "\n",
    "def get_outliers(data, col, m=2):\n",
    "    return data[(data[col] - np.mean(data[col])) < -1.0 * (m * np.std(data[col]))]\n",
    "outlier_df = get_outliers(val_eval_df, 'dice_coef', 2)\n",
    "outlier_df = outlier_df.sort_values('dice_coef')\n",
    "print(outlier_df.shape)\n",
    "outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_id in outlier_df.img_id.tolist():\n",
    "    print(img_id, outlier_df[outlier_df.img_id == img_id].values.tolist()[0][2])\n",
    "    test_img = get_image(img_id)\n",
    "\n",
    "    # Plot original image\n",
    "    actual_img = load_image_disk(img_id)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(actual_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Predict mask\n",
    "    pred_mask = model.predict(np.expand_dims(test_img, axis=0))\n",
    "    \n",
    "    # Plot predicted mask\n",
    "    pred_mask = np.squeeze(pred_mask)    \n",
    "    pred_mask = resize_img(pred_mask, (HEIGHT_ORIG, WIDTH_ORIG))\n",
    "    pred_mask[pred_mask <= 0.5] = 0\n",
    "    pred_mask[pred_mask > 0.5] = 1\n",
    "    \n",
    "    # Plot ground truth mask\n",
    "    mask = load_mask_disk(img_id)\n",
    "    mask = np.squeeze(mask)\n",
    "    mask = resize_img(mask, (HEIGHT_ORIG, WIDTH_ORIG))\n",
    "        \n",
    "    # Plot intersection (true_positives) of two masks\n",
    "    true_positives = pred_mask * mask\n",
    "    \n",
    "    # Plot false positives (pred_mask == 1 && mask == 0)\n",
    "    false_positives = np.zeros_like(mask)\n",
    "    false_positives[(pred_mask == 1) & (mask == 0)] = 1\n",
    "    \n",
    "    # Plot false negatives (pred_mask == 0 && mask == 1)\n",
    "    false_negatives = np.zeros_like(mask)\n",
    "    false_negatives[(pred_mask == 0) & (mask == 1)] = 1\n",
    "\n",
    "    # Plot true negatives (pred_mask == 0 && mask == 0)\n",
    "    true_negatives = np.zeros_like(mask)\n",
    "    true_negatives[(pred_mask == 0) & (mask == 0)] = 1\n",
    "    \n",
    "    # Plot merged mask \n",
    "    # Legend: \n",
    "    #   Red: false positives \n",
    "    #   Green: true positives\n",
    "    #   Blue: false negatives\n",
    "    #   Black: true negatives\n",
    "    #   White: background (unclassified pixels) - this should never be visible\n",
    "    rgb_merged_mask = np.zeros((HEIGHT_ORIG, WIDTH_ORIG, CHANNELS_ORIG))\n",
    "    rgb_merged_mask = 255 # White\n",
    "    rgb_true_positives = gray2rgb(true_positives)\n",
    "    rgb_false_positives = gray2rgb(false_positives)\n",
    "    rgb_false_negatives = gray2rgb(false_negatives)\n",
    "    rgb_true_negatives = gray2rgb(true_negatives)\n",
    "\n",
    "    rgb_merged_mask = rgb_true_positives + rgb_false_positives + rgb_false_negatives + rgb_true_negatives\n",
    "    rgb_merged_mask[true_positives == 1] = [0, 255, 0] # Green\n",
    "    rgb_merged_mask[false_positives == 1] = [255, 0, 0] # Red\n",
    "    rgb_merged_mask[false_negatives == 1] = [0, 0, 255] # Blue\n",
    "    rgb_merged_mask[true_negatives == 1] = [0, 0, 0] # Black\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(rgb_merged_mask)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper methods\n",
    "def rle_encode(mask_image):\n",
    "    pixels = mask_image.flatten()\n",
    "    # We avoid issues with '1' at the start or end (at the corners of \n",
    "    # the original image) by setting those pixels to '0' explicitly.\n",
    "    # We do not expect these to be non-zero for an accurate mask, \n",
    "    # so this should not harm the score.\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "    return runs\n",
    "\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def load_imgs(img_ids, folder=TRAIN_PATH):\n",
    "    imgs = []\n",
    "    for img_id in img_ids:\n",
    "        img = misc.imread(os.path.join(folder, img_id + \".jpg\"))\n",
    "        imgs.append(img)\n",
    "    return np.asarray(imgs)\n",
    "\n",
    "def resize_imgs(imgs, factor=0.1):\n",
    "    resized_imgs = []\n",
    "    for img in imgs:\n",
    "        resized_img = rescale(img, factor)\n",
    "        resized_imgs.append(resized_img)\n",
    "    return np.asarray(resized_imgs)\n",
    "\n",
    "def rescale_and_clean_masks(masks):\n",
    "    clean_masks = np.zeros((masks.shape[0], HEIGHT_ORIG, WIDTH_ORIG, 1), dtype=np.uint8)\n",
    "    for i in range(masks.shape[0]):        \n",
    "        mask = resize(masks[i], (HEIGHT_ORIG, WIDTH_ORIG, 1))\n",
    "        mask[mask <= 0.5] = 0\n",
    "        mask[mask > 0.5] = 1\n",
    "        clean_masks[i] = mask\n",
    "    return clean_masks\n",
    "\n",
    "def rle_masks(masks):  \n",
    "    rles = []\n",
    "    for i in range(masks.shape[0]):\n",
    "        rles.append(rle_to_string(rle_encode(masks[i])))\n",
    "    return rles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet_1024()\n",
    "# Here you have to specify the concrete name of your saved model\n",
    "model.load_weights(os.path.join(MODELS_PATH, 'model-1555053470.h5'))\n",
    "model.compile(loss=bce_dice_loss, optimizer=Adam(1e-5), metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img_path in os.listdir(TEST_PATH)[32000:32010]:\n",
    "    #print(img_id, outlier_df[outlier_df.img_id == img_id].values.tolist()[0][2])\n",
    "    #test_img = get_image(img_id)\n",
    "    img_id = get_img_id(img_path)\n",
    "    \n",
    "    # Plot original image\n",
    "    actual_img = load_image_disk(img_id, TEST_PATH)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(actual_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    test_img_cv2 = cv2.resize(actual_img, (new_shape[0], new_shape[1]))\n",
    "    \n",
    "    # Predict mask\n",
    "    pred_mask = model.predict(np.expand_dims(test_img_cv2, axis=0))\n",
    "    \n",
    "    # Plot predicted mask\n",
    "    pred_mask = np.squeeze(pred_mask)    \n",
    "    pred_mask = resize_img(pred_mask, (HEIGHT_ORIG, WIDTH_ORIG))\n",
    "    pred_mask[pred_mask <= 0.5] = 0\n",
    "    pred_mask[pred_mask > 0.5] = 1\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(pred_mask)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
