{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with Mask R-CNN\n",
    "# RSNA Pneumonia Detection Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the practical use of Mask R-CNN in combination with Transfer Learning, I found an interesting application for instance segmentation. It's the Kaggle Challenge: RSNA Pneumonia Detection Challenge.\n",
    "\n",
    "The company behind this challenge is Radiological Society of North America (RSNAÂ®), an international society of radiologists, medical physicists and other medical professionals. They see the potential for Machine Learning to solve the problem of detecting pneumonia in a simpler and automated way. Common diagnosing pneumonia requires review of a chest radiograph (CXR) by qualified experts. The disease pattern often manifests as an area of opacity on CXR, but there are many other conditions playing a role.\n",
    "\n",
    "So in this competition, the participants are called to support clinical institutions by building a machine learning algorithm in order to locate lung opacities on chest radiographs. Our model will be applied to segment all the the regions in the medical images and predicts the probability for a pneumonia. In other words the objective is to detect and draw a bounding box on each of the pneumonia opacities. Each image can have zero or many opacities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pydicom\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import glob\n",
    "from sklearn.model_selection import KFold\n",
    "#from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/input'\n",
    "\n",
    "# Directory to save logs and trained model, name it like you want\n",
    "ROOT_DIR = '/working'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Mask R-CNN GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://www.github.com/matterport/Mask_RCNN.git\n",
    "os.chdir('Mask_RCNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import for Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(os.path.join('Mask_RCNN'))  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download datasets on Kaggle: https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data\n",
    "train_dicom_dir = './input/stage_2_train_images'\n",
    "test_dicom_dir = './input/stage_2_test_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get COCO weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd coco_weight && wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
    "# !ls -lh mask_rcnn_coco.h5\n",
    "\n",
    "COCO_WEIGHTS_PATH = \"/my-ml-files/working/mask_rcnn_coco.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some setup functions and classes for Mask-RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicom_fps: list of the dicom image path and filenames\n",
    "#image_annotions: dictionary of the annotations keyed by the filenames\n",
    "#parsing the dataset: return a list of the image filenames and the annotations dictionary\n",
    "\n",
    "def get_dicom_fps(dicom_dir):\n",
    "    dicom_fps = glob.glob(dicom_dir+'/'+'*.dcm')\n",
    "    return list(set(dicom_fps))\n",
    "\n",
    "def parse_dataset(dicom_dir, anns): \n",
    "    image_fps = get_dicom_fps(dicom_dir)\n",
    "    image_annotations = {fp: [] for fp in image_fps}\n",
    "    for index, row in anns.iterrows(): \n",
    "        fp = os.path.join(dicom_dir, row['patientId']+'.dcm')\n",
    "        image_annotations[fp].append(row)\n",
    "    return image_fps, image_annotations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following parameters are not optimal!\n",
    "\n",
    "class DetectorConfig(Config):\n",
    "    \"\"\"Configuration for training pneumonia detection on the RSNA pneumonia dataset.\n",
    "    Overrides values in the base Config class.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration name  \n",
    "    NAME = 'pneumonia'\n",
    "    \n",
    "    # 1 GPU and 8 images per GPU\n",
    "    # Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "    \n",
    "    # play with some numbers!\n",
    "    BACKBONE = 'resnet50' #'resnet100'\n",
    "    \n",
    "    NUM_CLASSES = 2  # background + pneumonia classes\n",
    "    \n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    #RPN_ANCHOR_SCALES = (16, 32, 64, 128)\n",
    "    TRAIN_ROIS_PER_IMAGE = 32 #16\n",
    "    MAX_GT_INSTANCES = 4 #3\n",
    "    DETECTION_MAX_INSTANCES = 3\n",
    "    DETECTION_MIN_CONFIDENCE = 0.78  #0.7\n",
    "    DETECTION_NMS_THRESHOLD = 0.01 #0.3\n",
    "\n",
    "    STEPS_PER_EPOCH = 200 #500\n",
    "\n",
    "config = DetectorConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class for training pneumonia detection on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorDataset(utils.Dataset):\n",
    "\n",
    "    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        # Add classes\n",
    "        self.add_class('pneumonia', 1, 'Lung Opacity')\n",
    "        \n",
    "        # add images \n",
    "        for i, fp in enumerate(image_fps):\n",
    "            annotations = image_annotations[fp]\n",
    "            self.add_image('pneumonia', image_id=i, path=fp, \n",
    "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
    "            \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        fp = info['path']\n",
    "        ds = pydicom.read_file(fp)\n",
    "        image = ds.pixel_array\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "        count = len(annotations)\n",
    "        if count == 0:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
    "            class_ids = np.zeros((1,), dtype=np.int32)\n",
    "        else:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
    "            class_ids = np.zeros((count,), dtype=np.int32)\n",
    "            for i, a in enumerate(annotations):\n",
    "                if a['Target'] == 1:\n",
    "                    x = int(a['x'])\n",
    "                    y = int(a['y'])\n",
    "                    w = int(a['width'])\n",
    "                    h = int(a['height'])\n",
    "                    mask_instance = mask[:, :, i].copy()\n",
    "                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)\n",
    "                    mask[:, :, i] = mask_instance\n",
    "                    class_ids[i] = 1\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the annotation data, parse the dataset, and view dicom fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "from pathlib import Path\n",
    "mypath = Path().absolute()\n",
    "print(mypath)\n",
    "\n",
    "anns = pd.read_csv('./input/stage_labels.csv')\n",
    "anns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fps, image_annotations = parse_dataset(train_dicom_dir, anns=anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pydicom.read_file(image_fps[0]) # read dicom image from filepath \n",
    "image = ds.pixel_array # get image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size: 1024 x 1024\n",
    "ORIG_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fps_list = list(image_fps)\n",
    "random.seed(42)\n",
    "random.shuffle(image_fps_list)\n",
    "val_size = 1500\n",
    "image_fps_val = image_fps_list[:val_size]\n",
    "image_fps_train = image_fps_list[val_size:]\n",
    "\n",
    "print(len(image_fps_train), len(image_fps_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and prepare the training dataset using the DetectorDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training dataset\n",
    "dataset_train = DetectorDataset(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show annotation for a DICOM image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding box with (x, y) of the the top left corner as well as the width and height.\n",
    "test_fp = random.choice(image_fps_train)\n",
    "image_annotations[test_fp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = DetectorDataset(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and display random sample and their bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = [0]\n",
    "while class_ids[0] == 0:  ## look for a mask\n",
    "    image_id = random.choice(dataset_train.image_ids)\n",
    "    image_fp = dataset_train.image_reference(image_id)\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "masked = np.zeros(image.shape[:2])\n",
    "for i in range(mask.shape[2]):\n",
    "    masked += image[:, :, 0] * mask[:, :, i]\n",
    "plt.imshow(masked, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "print(image_fp)\n",
    "print(class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = iaa.Sequential([\n",
    "    iaa.OneOf([ ## geometric transform\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.04)},\n",
    "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n",
    "            rotate=(-2, 2),\n",
    "            shear=(-1, 1),\n",
    "        ),\n",
    "        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n",
    "    ]),\n",
    "    iaa.OneOf([ ## brightness or contrast\n",
    "        iaa.Multiply((0.9, 1.1)),\n",
    "        iaa.ContrastNormalization((0.9, 1.1)),\n",
    "    ]),\n",
    "    iaa.OneOf([ ## blur or sharpen\n",
    "        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n",
    "        iaa.Sharpen(alpha=(0.0, 0.1)),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "# test augmentation on image\n",
    "imggrid = augmentation.draw_grid(image[:, :, 0], cols=5, rows=2)\n",
    "plt.figure(figsize=(30, 12))\n",
    "_ = plt.imshow(imggrid[:, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to train the model. \n",
    "Note: the following model is for demonstration purpose only.\n",
    "\n",
    "- dataset_train and dataset_val from DetectorDataset\n",
    "- DetectorDataset loads images from image files and masks from the annotation data\n",
    "- model: Mask-RCNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir=ROOT_DIR)\n",
    "\n",
    "model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n",
    "    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "    \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.006\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train heads with higher lr for more learning speed\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            epochs=1,\n",
    "            layers='heads',\n",
    "            augmentation=None)  \n",
    "\n",
    "history = model.keras_model.history.history\n",
    "\n",
    "#now with all layers and augmentation included!\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            epochs=6,\n",
    "            layers='all',\n",
    "            augmentation=augmentation)\n",
    "\n",
    "new_history = model.keras_model.history.history\n",
    "for k in new_history: history[k] = history[k] + new_history[k]\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=LEARNING_RATE/5,\n",
    "            epochs=16,\n",
    "            layers='all',\n",
    "            augmentation=augmentation)\n",
    "\n",
    "new_history = model.keras_model.history.history\n",
    "for k in new_history: history[k] = history[k] + new_history[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1,len(next(iter(history.values())))+1)\n",
    "pd.DataFrame(history, index=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(epochs, history[\"loss\"], label=\"Train loss\")\n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"Valid loss\")\n",
    "plt.legend()\n",
    "plt.subplot(132)\n",
    "plt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"Train class ce\")\n",
    "plt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"Valid class ce\")\n",
    "plt.legend()\n",
    "plt.subplot(133)\n",
    "plt.plot(epochs, history[\"mrcnn_bbox_loss\"], label=\"Train box loss\")\n",
    "plt.plot(epochs, history[\"val_mrcnn_bbox_loss\"], label=\"Valid box loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(history[\"val_loss\"])\n",
    "print(\"Best Epoch:\", best_epoch + 1, history[\"val_loss\"][best_epoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select trained model \n",
    "dir_names = next(os.walk(model.model_dir))[1]\n",
    "key = config.NAME.lower()\n",
    "dir_names = filter(lambda f: f.startswith(key), dir_names)\n",
    "dir_names = sorted(dir_names)\n",
    "\n",
    "if not dir_names:\n",
    "    import errno\n",
    "    raise FileNotFoundError(\n",
    "        errno.ENOENT,\n",
    "        \"Could not find model directory under {}\".format(self.model_dir))\n",
    "    \n",
    "fps = []\n",
    "# Pick last directory\n",
    "for d in dir_names: \n",
    "    dir_name = os.path.join(model.model_dir, d)\n",
    "    # Find the last checkpoint\n",
    "    checkpoints = next(os.walk(dir_name))[2]\n",
    "    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n",
    "    checkpoints = sorted(checkpoints)\n",
    "    if not checkpoints:\n",
    "        print('No weight files in {}'.format(dir_name))\n",
    "    else:\n",
    "        checkpoint = os.path.join(dir_name, checkpoints[best_epoch])\n",
    "        fps.append(checkpoint)\n",
    "\n",
    "model_path = sorted(fps)[-1]\n",
    "print('Found model {}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(DetectorConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode='inference', \n",
    "                          config=inference_config,\n",
    "                          model_dir=ROOT_DIR)\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set color for class\n",
    "def get_colors_for_class_ids(class_ids):\n",
    "    colors = []\n",
    "    for class_id in class_ids:\n",
    "        if class_id == 1:\n",
    "            colors.append((.941, .204, .204))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the validation data to check the expected bounding box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the validation dataset \n",
    "dataset = dataset_val\n",
    "fig = plt.figure(figsize=(10, 30))\n",
    "\n",
    "for i in range(6):\n",
    "\n",
    "    image_id = random.choice(dataset.image_ids)\n",
    "    \n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config, \n",
    "                               image_id, use_mini_mask=False)\n",
    "    \n",
    "    print(original_image.shape)\n",
    "    plt.subplot(6, 2, 2*i + 1)\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                                dataset.class_names,\n",
    "                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n",
    "    \n",
    "    plt.subplot(6, 2, 2*i + 2)\n",
    "    results = model.detect([original_image]) #, verbose=1)\n",
    "    r = results[0]\n",
    "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                dataset.class_names, r['scores'], \n",
    "                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Predict Test dataset and get submission file for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filenames of test images\n",
    "test_image_fps = get_dicom_fps(test_dicom_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test images, write to submission file\n",
    "def predict(image_fps, filepath='submission.csv', min_conf=0.95):\n",
    "    resize_factor = ORIG_SIZE / config.IMAGE_SHAPE[0]\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.write(\"patientId,PredictionString\\n\")\n",
    "\n",
    "        for image_id in tqdm(image_fps):\n",
    "            ds = pydicom.read_file(image_id)\n",
    "            image = ds.pixel_array\n",
    "            if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "                image = np.stack((image,) * 3, -1)\n",
    "            image, window, scale, padding, crop = utils.resize_image(\n",
    "                image,\n",
    "                min_dim=config.IMAGE_MIN_DIM,\n",
    "                min_scale=config.IMAGE_MIN_SCALE,\n",
    "                max_dim=config.IMAGE_MAX_DIM,\n",
    "                mode=config.IMAGE_RESIZE_MODE)\n",
    "\n",
    "            patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
    "\n",
    "            results = model.detect([image])\n",
    "            r = results[0]\n",
    "\n",
    "            out_str = \"\"\n",
    "            out_str += patient_id\n",
    "            out_str += \",\"\n",
    "            assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n",
    "            if len(r['rois']) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                num_instances = len(r['rois'])\n",
    "\n",
    "                for i in range(num_instances):\n",
    "                    if r['scores'][i] > min_conf:\n",
    "                        out_str += ' '\n",
    "                        out_str += str(round(r['scores'][i], 2))\n",
    "                        out_str += ' '\n",
    "\n",
    "                        # x1, y1, width, height\n",
    "                        x1 = r['rois'][i][1]\n",
    "                        y1 = r['rois'][i][0]\n",
    "                        width = r['rois'][i][3] - x1\n",
    "                        height = r['rois'][i][2] - y1\n",
    "                        bboxes_str = \"{} {} {} {}\".format(x1*resize_factor, y1*resize_factor, \\\n",
    "                                                           width*resize_factor, height*resize_factor)\n",
    "                        out_str += bboxes_str\n",
    "\n",
    "            file.write(out_str+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
